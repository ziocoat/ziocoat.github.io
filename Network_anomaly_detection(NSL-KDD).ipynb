{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d770efa",
   "metadata": {},
   "source": [
    "# 석사 학위 논문\n",
    "# Data Preprocessing\n",
    "\n",
    "\n",
    "- Label Encoding\n",
    "- StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fef68db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label :  0    67343\n",
      "1    58630\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "Test Label :  1    12833\n",
      "0     9711\n",
      "Name: label, dtype: int64\n",
      "인코딩 변환값:  [20 44 49 ... 54 30 20]\n",
      "인코딩 변환값:  [9 9 5 ... 9 5 9]\n",
      "인코딩 변환값:  [1 2 1 ... 1 1 1]\n",
      "인코딩 변환값:  [45 45 19 ... 22 11 52]\n",
      "인코딩 변환값:  [1 1 9 ... 9 9 1]\n",
      "인코딩 변환값:  [1 1 1 ... 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "import time\n",
    "\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\",'?']\n",
    "\n",
    "df = pd.read_csv('./KDDTrain+.txt', names = col_names)\n",
    "df_test = pd.read_csv('./KDDTest+.txt', names = col_names)\n",
    "\n",
    "df = pd.read_csv('./KDDTrain+.txt', names = col_names)\n",
    "df_test = pd.read_csv('./KDDTest+.txt', names = col_names)\n",
    "\n",
    "df = df.drop(['?'], axis= 1)\n",
    "df_test = df_test.drop(['?'], axis= 1)\n",
    "\n",
    "labeldf=df['label']\n",
    "labeldf_test=df_test['label']\n",
    "\n",
    "\n",
    "\n",
    "newlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,    \n",
    "                           'ipsweep' : 1,'nmap' : 1,'portsweep' : 1,'satan' : 1\n",
    "                           ,'ftp_write': 1,'guess_passwd': 1,'imap': 1,'multihop': 1,'phf': 1,'spy': 1,'warezclient':1,'warezmaster': 1,\n",
    "                           'buffer_overflow': 1,'loadmodule': 1,'perl': 1,'rootkit': 1})\n",
    "newlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 1,'nmap' : 1,'portsweep' : 1,'satan' : 1,'mscan' : 1,'saint' : 1\n",
    "                           ,'ftp_write': 1,'guess_passwd': 1,'imap': 1,'multihop': 1,'phf': 1,'spy': 1,'warezclient': 1,'warezmaster': 1,'sendmail': 1,'named': 1,'snmpgetattack': 1,'snmpguess': 1,'xlock': 1,'xsnoop': 1,'httptunnel': 1,\n",
    "                           'buffer_overflow': 1,'loadmodule': 1,'perl': 1,'rootkit': 1,'ps': 1,'sqlattack': 1,'xterm': 1})\n",
    "df['label'] = newlabeldf\n",
    "df_test['label'] = newlabeldf_test\n",
    "print('Train Label : ',df['label'].value_counts() , '\\n\\n'\n",
    "      'Test Label : ',df_test['label'].value_counts())\n",
    "\n",
    "\n",
    "df_test\n",
    "\n",
    "def label(df, test):\n",
    "    y_train = df['label']\n",
    "    y_test = test['label']\n",
    "    \n",
    "    X_train = df.drop(['label'],axis = 1)\n",
    "    X_test = test.drop(['label'],axis=1)\n",
    "    return y_train, y_test, X_train, X_test\n",
    "\n",
    "\n",
    "y_train, y_test, X_train, X_test = label(df, df_test)\n",
    "\n",
    "\n",
    "def label(df):\n",
    "    \n",
    "    service = df['service']\n",
    "    encoder = LabelEncoder() \n",
    "    encoder.fit(service)\n",
    "    services = encoder.transform(service)  \n",
    "    print('인코딩 변환값: ', services)\n",
    "\n",
    "    df['service'] = services\n",
    "\n",
    "    flag = df['flag']\n",
    "    encoder = LabelEncoder() \n",
    "    encoder.fit(flag)\n",
    "    flags = encoder.transform(flag)  \n",
    "    print('인코딩 변환값: ', flags)\n",
    "\n",
    "    df['flag'] = flags\n",
    "\n",
    "    protocol_type = df['protocol_type']\n",
    "    encoder = LabelEncoder() \n",
    "    encoder.fit(protocol_type)\n",
    "    protocol_types = encoder.transform(protocol_type)  \n",
    "    print('인코딩 변환값: ', protocol_types)\n",
    "\n",
    "    df['protocol_type'] = protocol_types\n",
    "    return df\n",
    "    \n",
    "total_df = X_train, X_test\n",
    "    \n",
    "for i in total_df:\n",
    "    a = label(i)\n",
    "    \n",
    "\n",
    "def accuracy(y_test, pred):\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    #confusion = skplt.metrics.plot_confusion_matrix(y_test, pred)\n",
    "    a = np.round(accuracy*100,2),np.round(precision*100,2),np.round(recall*100,2),np.round(f1*100,2)\n",
    "    print('Accuracy \\t {0:.2f}% ,\\n Precision \\t{1:.2f}%,\\n Recall \\t{2:.2f}%,\\n F1_score \\t{3:.2f}%'.format(accuracy*100,precision*100,\n",
    "                                      recall*100, f1*100))\n",
    "    return a\n",
    "    \n",
    "total_colNames=list(X_train)\n",
    "total_colNames_test=list(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64e0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, pred):\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    #confusion = skplt.metrics.plot_confusion_matrix(y_test, pred)\n",
    "    a = np.round(accuracy*100,2),np.round(precision*100,2),np.round(recall*100,2),np.round(f1*100,2)\n",
    "    print('Accuracy \\t {0:.2f}% ,\\n Precision \\t{1:.2f}%,\\n Recall \\t{2:.2f}%,\\n F1_score \\t{3:.2f}%'.format(accuracy*100,precision*100,\n",
    "                                      recall*100, f1*100))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da971bfa",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "- Feature Selection\n",
    "    * Sklearn - SelectKBest, f_classif\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d3c48b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [19] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "for i in range(41,42):\n",
    "    start = time.time()\n",
    "\n",
    "    selector = SelectKBest(f_classif , k=i)\n",
    "    X_st = selector.fit_transform(X_train, y_train)\n",
    "    X_st_test = selector.transform(X_test)\n",
    "    true=selector.get_support()\n",
    "    total_colNames_index=[z for z, x in enumerate(true) if x]\n",
    "    skb_total=list( total_colNames[i] for i in total_colNames_index )\n",
    "    \n",
    "    sc  = StandardScaler()\n",
    "    new_df = sc.fit_transform(X_st)\n",
    "    new_df_test = sc.fit_transform(X_st_test)\n",
    "    \n",
    "    X_total = pd.DataFrame(new_df, columns = skb_total )\n",
    "    X_total_test = pd.DataFrame(new_df_test, columns = skb_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62443a",
   "metadata": {},
   "source": [
    "# Individual Algorithm for Stacking Model\n",
    "- Decision Tree, LGBM, KNN, Adaboost, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41623443",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25165534019470215\n",
      "Accuracy \t 83.52% ,\n",
      " Precision \t86.48%,\n",
      " Recall \t84.85%,\n",
      " F1_score \t85.66%\n",
      "(83.52, 86.48, 84.85, 85.66)\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth= 5, random_state =15)\n",
    "start = time.time()\n",
    "dt_clf.fit(X_total, y_train)\n",
    "dt_pred = dt_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "print(accuracy(dt_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1cef11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.353024959564209\n",
      "Accuracy \t 83.50% ,\n",
      " Precision \t79.23%,\n",
      " Recall \t90.61%,\n",
      " F1_score \t84.54%\n",
      "(83.5, 79.23, 90.61, 84.54)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lgbm_clf = LGBMClassifier(max_depth = 4, num_leaves = 36 ,random_state = 1)\n",
    "lgbm_clf.fit(X_total, y_train)\n",
    "lgbm_pred = lgbm_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "print(accuracy(lgbm_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3980bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.31369495391846\n",
      "Accuracy \t 77.21% ,\n",
      " Precision \t61.86%,\n",
      " Recall \t97.03%,\n",
      " F1_score \t75.56%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(77.21, 61.86, 97.03, 75.56)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors =6)\n",
    "start = time.time()\n",
    "\n",
    "knn_clf.fit(X_total, y_train)\n",
    "knn_pred = knn_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "accuracy(knn_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39af0329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.011828660964966\n",
      "Accuracy \t 79.17% ,\n",
      " Precision \t71.53%,\n",
      " Recall \t89.80%,\n",
      " F1_score \t79.63%\n",
      "(79.17, 71.53, 89.8, 79.63)\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(random_state = 1,n_estimators=100)\n",
    "start = time.time()\n",
    "\n",
    "ada_clf.fit(X_total, y_train)\n",
    "ada_pred = ada_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "print(accuracy(ada_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eaf2bf5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.203289270401001\n",
      "Accuracy \t 78.47% ,\n",
      " Precision \t68.53%,\n",
      " Recall \t91.52%,\n",
      " F1_score \t78.37%\n",
      "(78.47, 68.53, 91.52, 78.37)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "lr_clf.fit(X_total, y_train)\n",
    "lr_pred = lr_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "print(accuracy(lr_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52262f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clf =  LGBMClassifier(random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d74c38",
   "metadata": {},
   "source": [
    "# Stacking Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "194e1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking(clf1,clf2,clf3,clf4,clf5 ,final_clf,x_train,x_test,y_train,y_test):\n",
    "\n",
    "    clf1 = DecisionTreeClassifier(max_depth= 5, random_state =15)\n",
    "    clf1.fit(X_total, y_train)\n",
    "    dt_pred = clf1.predict(X_total_test)\n",
    "\n",
    "    clf2 = LGBMClassifier(max_depth = 4, num_leaves = 36 ,random_state = 1)\n",
    "    clf2.fit(X_total, y_train)\n",
    "    lgbm_pred = clf2.predict(X_total_test)\n",
    "\n",
    "    clf3 = KNeighborsClassifier(n_neighbors =6)\n",
    "    clf3.fit(X_total, y_train)\n",
    "    knn_pred = clf3.predict(X_total_test)\n",
    "\n",
    "    clf4 = AdaBoostClassifier(random_state = 1,n_estimators=100)\n",
    "    clf4.fit(X_total, y_train)\n",
    "    ada_pred = clf4.predict(X_total_test)\n",
    "\n",
    "    clf5 = LogisticRegression(max_iter = 1000)\n",
    "    clf5.fit(X_total, y_train)\n",
    "    lr_pred = clf5.predict(X_total_test)\n",
    "\n",
    "    preds = np.array([   dt_pred, lgbm_pred,knn_pred, ada_pred, lr_pred])\n",
    "    preds= np.transpose(preds) # or pred.T\n",
    "    final_clf =  LGBMClassifier(random_state = 1)\n",
    "    final_clf.fit(preds, y_test)\n",
    "    finalr_pred = final_clf.predict(preds)\n",
    "    print(preds.shape, y_test.shape)\n",
    "    print('Stacking 모델의 예측 정확도 : ')\n",
    "    b= pd.DataFrame(accuracy(finalr_pred, y_test))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e34a1",
   "metadata": {},
   "source": [
    "# Optimal Features in the Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9600da6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [19] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'land', 'wrong_fragment', 'hot', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'is_guest_login', 'count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']\n",
      "SelectKBest의 갯수 35\n",
      "feature 개수 :  35\n",
      "(22544, 5) (22544,)\n",
      "Stacking 모델의 예측 정확도 : \n",
      "Accuracy \t 90.42% ,\n",
      " Precision \t97.97%,\n",
      " Recall \t86.88%,\n",
      " F1_score \t92.09%\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "b = pd.DataFrame(columns=range(35,36))\n",
    "c = []\n",
    "for i in range(35,36):\n",
    "    start = time.time()\n",
    "\n",
    "    selector = SelectKBest(f_classif , k=i)\n",
    "    X_st = selector.fit_transform(X_train, y_train)\n",
    "    X_st_test = selector.transform(X_test)\n",
    "    true=selector.get_support()\n",
    "    total_colNames_index=[z for z, x in enumerate(true) if x]\n",
    "    skb_total=list( total_colNames[i] for i in total_colNames_index )\n",
    "    print(skb_total)\n",
    "    print('SelectKBest의 갯수',len(skb_total))\n",
    "    \n",
    "    sc  = StandardScaler()\n",
    "    new_df = sc.fit_transform(X_st)\n",
    "    new_df_test = sc.fit_transform(X_st_test)\n",
    "    \n",
    "    X_total = pd.DataFrame(new_df, columns = skb_total )\n",
    "    X_total_test = pd.DataFrame(new_df_test, columns = skb_total)\n",
    "    print('feature 개수 : ',len(skb_total))\n",
    "    a = stacking(  dt_clf, lgbm_clf, knn_clf,ada_clf,lr_clf, final_clf,X_total,X_total_test\n",
    "             ,y_train,y_test)\n",
    "    a = a[0]\n",
    "    print('----------------')\n",
    "    b[i] = a\n",
    "    end = time.time()\n",
    "    total_time = end - start\n",
    "    c.append(total_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63501d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.to_csv('./f_classif.csv')\n",
    "\n",
    "\n",
    "c = pd.DataFrame(c)\n",
    "c = c.T\n",
    "\n",
    "\n",
    "c.to_csv('./f_classif_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83d761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
