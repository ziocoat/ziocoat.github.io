{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D, Conv2D, Conv1D, Dropout\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "import timeit\n",
    "\n",
    "df = pd.read_csv('./UNSW_NB15_testing-set.csv')\n",
    "df_test = pd.read_csv('./UNSW_NB15_training-set.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
       "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
       "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
       "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
       "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
       "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
       "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
       "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값:  [0 0 0 ... 0 0 0]\n",
      "인코딩 변환값:  [4 4 4 ... 4 4 4]\n",
      "인코딩 변환값:  [117 117 117 ...   6   6 117]\n",
      "인코딩 변환값:  [0 0 0 ... 2 2 2]\n",
      "인코딩 변환값:  [2 2 2 ... 3 3 3]\n",
      "인코딩 변환값:  [113 113 113 ... 119 119 119]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def label(df, test):\n",
    "    y_train = df['label']\n",
    "    y_test = test['label']\n",
    "    \n",
    "    X_train = df.drop(['label'],axis = 1)\n",
    "    X_test = test.drop(['label'],axis=1)\n",
    "    return y_train, y_test, X_train, X_test\n",
    "\n",
    "\n",
    "y_train, y_test, X_train, X_test = label(df, df_test)\n",
    "\n",
    "\n",
    "def label(df):\n",
    "    \n",
    "    service = df['service']\n",
    "    encoder = LabelEncoder() \n",
    "    encoder.fit(service)\n",
    "    services = encoder.transform(service)  \n",
    "    print('인코딩 변환값: ', services)\n",
    "\n",
    "    df['service'] = services\n",
    "\n",
    "    flag = df['state']\n",
    "    encoder = LabelEncoder() \n",
    "    encoder.fit(flag)\n",
    "    flags = encoder.transform(flag)  \n",
    "    print('인코딩 변환값: ', flags)\n",
    "\n",
    "    df['state'] = flags\n",
    "\n",
    "    protocol_type = df['proto']\n",
    "    encoder = LabelEncoder() \n",
    "    encoder.fit(protocol_type)\n",
    "    protocol_types = encoder.transform(protocol_type)  \n",
    "    print('인코딩 변환값: ', protocol_types)\n",
    "\n",
    "    df['proto'] = protocol_types\n",
    "    return df\n",
    "    \n",
    "total_df = X_train, X_test\n",
    "    \n",
    "for i in total_df:\n",
    "    a = label(i)\n",
    "    \n",
    "\n",
    "def accuracy(y_test, pred):\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    #confusion = skplt.metrics.plot_confusion_matrix(y_test, pred)\n",
    "    a = np.round(accuracy*100,2),np.round(precision*100,2),np.round(recall*100,2),np.round(f1*100,2)\n",
    "    print('Accuracy \\t {0:.2f}% ,\\n Precision \\t{1:.2f}%,\\n Recall \\t{2:.2f}%,\\n F1_score \\t{3:.2f}%'.format(accuracy*100,precision*100,\n",
    "                                      recall*100, f1*100))\n",
    "    return a\n",
    "    \n",
    "total_colNames=list(X_train)\n",
    "total_colNames_test=list(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['attack_cat'], axis = 1, inplace = True)\n",
    "X_test.drop(['attack_cat'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest의 갯수 43\n",
      "53.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif \n",
    "\n",
    "for i in range(43,44):\n",
    "    selector = SelectKBest(chi2, k=i)\n",
    "    X_st = selector.fit_transform(X_train, y_train)\n",
    "    X_st_test = selector.transform(X_test)\n",
    "    true=selector.get_support()\n",
    "    total_colNames_index=[z for z, x in enumerate(true) if x]\n",
    "    skb_total=list( total_colNames[i] for i in total_colNames_index )\n",
    "    print('SelectKBest의 갯수',len(skb_total))\n",
    "    \n",
    "    sc  = StandardScaler()\n",
    "    new_df = sc.fit_transform(X_st)\n",
    "    new_df_test = sc.fit_transform(X_st_test)\n",
    "    \n",
    "    X_total = pd.DataFrame(new_df, columns = skb_total )\n",
    "    X_total_test = pd.DataFrame(new_df_test, columns = skb_total)\n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "    dt_clf.fit(X_total, y_train)\n",
    "    total_dt_pred = dt_clf.predict(X_total_test)\n",
    "    print(np.round(accuracy_score(total_dt_pred, y_test)*100,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy \t 84.70% ,\n",
      " Precision \t86.14%,\n",
      " Recall \t90.90%,\n",
      " F1_score \t88.46%\n",
      "(84.7, 86.14, 90.9, 88.46)\n",
      "126.80517053604126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import time\n",
    "    \n",
    "start = time.time()\n",
    "svm = SVC(kernel='rbf')\n",
    "svm.fit(X_total, y_train)\n",
    "svm_pred =svm.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(accuracy(svm_pred, y_test))\n",
    "print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6070976257324219\n",
      "Accuracy \t 41.87% ,\n",
      " Precision \t53.63%,\n",
      " Recall \t57.87%,\n",
      " F1_score \t55.67%\n",
      "(41.87, 53.63, 57.87, 55.67)\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier( random_state =15)\n",
    "start = time.time()\n",
    "dt_clf.fit(X_total, y_train)\n",
    "dt_pred = dt_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "print(accuracy(dt_pred, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9002072811126709\n",
      "Accuracy \t 30.52% ,\n",
      " Precision \t37.96%,\n",
      " Recall \t48.66%,\n",
      " F1_score \t42.65%\n",
      "(30.52, 37.96, 48.66, 42.65)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lgbm_clf = LGBMClassifier(random_state = 1)\n",
    "lgbm_clf.fit(X_total, y_train)\n",
    "lgbm_pred = lgbm_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "print(accuracy(lgbm_pred, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211.8557288646698\n",
      "Accuracy \t 79.77% ,\n",
      " Precision \t76.36%,\n",
      " Recall \t92.61%,\n",
      " F1_score \t83.71%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(79.77, 76.36, 92.61, 83.71)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors =6)\n",
    "start = time.time()\n",
    "\n",
    "knn_clf.fit(X_total, y_train)\n",
    "knn_pred = knn_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "accuracy(knn_pred, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.258786916732788\n",
      "Accuracy \t 73.03% ,\n",
      " Precision \t67.88%,\n",
      " Recall \t90.05%,\n",
      " F1_score \t77.41%\n",
      "(73.03, 67.88, 90.05, 77.41)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth= 7,random_state= 1)\n",
    "rf_clf.fit(X_total, y_train)\n",
    "rf_pred = rf_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "print(accuracy(rf_pred, y_test))\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1825098991394043\n",
      "Accuracy \t 73.61% ,\n",
      " Precision \t65.45%,\n",
      " Recall \t93.94%,\n",
      " F1_score \t77.15%\n",
      "(73.61, 65.45, 93.94, 77.15)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "nb_clf = BernoulliNB()\n",
    "nb_clf.fit(X_total, y_train)\n",
    "nb_pred = nb_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "print(accuracy(nb_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.367164850234985\n",
      "Accuracy \t 28.39% ,\n",
      " Precision \t37.84%,\n",
      " Recall \t46.78%,\n",
      " F1_score \t41.84%\n",
      "(28.39, 37.84, 46.78, 41.84)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(random_state = 1)\n",
    "start = time.time()\n",
    "\n",
    "ada_clf.fit(X_total, y_train)\n",
    "ada_pred = ada_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "print(accuracy(ada_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6216328144073486\n",
      "Accuracy \t 85.40% ,\n",
      " Precision \t87.55%,\n",
      " Recall \t90.68%,\n",
      " F1_score \t89.09%\n",
      "(85.4, 87.55, 90.68, 89.09)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "lr_clf.fit(X_total, y_train)\n",
    "lr_pred = lr_clf.predict(X_total_test)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "print(total)\n",
    "print(accuracy(lr_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clf =  LGBMClassifier(random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking(clf1,clf2,clf3,clf4,clf5,clf6, clf8, clf9 ,final_clf,x_train,x_test,y_train,y_test):\n",
    "\n",
    "    \n",
    "    clf1 = SVC(kernel='rbf')\n",
    "    clf1 .fit(X_total, y_train)\n",
    "    svm_pred =clf1 .predict(X_total_test)\n",
    "\n",
    "    clf2 = DecisionTreeClassifier(max_depth= 5)\n",
    "    clf2.fit(X_total, y_train)\n",
    "    dt_pred = clf2.predict(X_total_test)\n",
    "\n",
    "    clf3 = LGBMClassifier(max_depth = 7, num_leaves = 36)\n",
    "    clf3.fit(X_total, y_train)\n",
    "    lgbm_pred = clf3.predict(X_total_test)\n",
    "\n",
    "    clf4 = KNeighborsClassifier(n_neighbors =5)\n",
    "    clf4.fit(X_total, y_train)\n",
    "    knn_pred = clf4.predict(X_total_test)\n",
    "\n",
    "  \n",
    "    clf5 = RandomForestClassifier(max_depth= 7,random_state= 1)\n",
    "    clf5.fit(X_total, y_train)\n",
    "    rf_pred = clf5.predict(X_total_test)\n",
    "\n",
    "\n",
    "    clf6 = BernoulliNB()\n",
    "    clf6.fit(X_total, y_train)\n",
    "    nb_pred = clf6.predict(X_total_test)\n",
    "    def random_nomal_initializer_with_stddev_1():\n",
    "        return tf.keras.initializers.RandomNormal(mean = 0.0, stddev=1.0, seed=None)\n",
    "\n",
    "\n",
    "\n",
    "    def ann_model():\n",
    "        ann = Sequential()\n",
    "        ann.add(Dense(41,\n",
    "                    activation = 'relu',\n",
    "                    kernel_initializer =random_nomal_initializer_with_stddev_1(),\n",
    "                    bias_initializer = random_nomal_initializer_with_stddev_1()))\n",
    "\n",
    "        ann.add(Dense(20, activation = 'relu',\n",
    "                     kernel_initializer =random_nomal_initializer_with_stddev_1(),\n",
    "                     bias_initializer = random_nomal_initializer_with_stddev_1()))\n",
    "        ann.add(Dense(10, activation = 'relu',\n",
    "                     kernel_initializer =random_nomal_initializer_with_stddev_1(),\n",
    "                     bias_initializer = random_nomal_initializer_with_stddev_1()))\n",
    "        ann.add(Dense(5, activation = 'relu',\n",
    "                     kernel_initializer =random_nomal_initializer_with_stddev_1(),\n",
    "                     bias_initializer = random_nomal_initializer_with_stddev_1()))\n",
    "\n",
    "\n",
    "        ann.add(Dense(1,activation = 'sigmoid'))\n",
    "        ann.compile(loss = 'binary_crossentropy', optimizer = 'Nadam', metrics = ['accuracy'])\n",
    "        return ann\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    clf8 = AdaBoostClassifier(random_state = 1,n_estimators=100)\n",
    "    clf8.fit(X_total, y_train)\n",
    "    ada_pred = clf8.predict(X_total_test)\n",
    "\n",
    "    clf9 = LogisticRegression(max_iter = 1000)\n",
    "    clf9.fit(X_total, y_train)\n",
    "    lr_pred = clf9.predict(X_total_test)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    preds = np.array([svm_pred, dt_pred, lgbm_pred,knn_pred,rf_pred, nb_pred,ada_pred, lr_pred])\n",
    "    preds= np.transpose(preds) # or pred.T\n",
    "    final_clf =  LGBMClassifier(random_state = 1)\n",
    "    final_clf.fit(preds, y_test)\n",
    "    finalr_pred = final_clf.predict(preds)\n",
    "    print(preds.shape, y_test.shape)\n",
    "    print('Stacking 모델의 예측 정확도 : ')\n",
    "    b= pd.DataFrame(accuracy(finalr_pred, y_test))\n",
    "    accuracy(finalr_pred, y_test)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports']\n",
      "SelectKBest의 갯수 43\n",
      "feature 개수 :  43\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stacking' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-ebc5a6ac36f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mX_total_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskb_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'feature 개수 : '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskb_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     a = stacking(svm,  dt_clf, lgbm_clf, knn_clf,rf_pred,nb_pred,ada_clf,lr_clf, final_clf,X_total,X_total_test\n\u001b[0m\u001b[0;32m     25\u001b[0m              ,y_train,y_test)\n\u001b[0;32m     26\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stacking' is not defined"
     ]
    }
   ],
   "source": [
    "import time \n",
    "from sklearn.feature_selection import f_classif \n",
    "b = pd.DataFrame(columns=range(43,44))\n",
    "c = []\n",
    "for i in range(43,44):\n",
    "    start = time.time()\n",
    "\n",
    "    selector = SelectKBest(f_classif , k=i)\n",
    "    X_st = selector.fit_transform(X_train, y_train)\n",
    "    X_st_test = selector.transform(X_test)\n",
    "    true=selector.get_support()\n",
    "    total_colNames_index=[z for z, x in enumerate(true) if x]\n",
    "    skb_total=list( total_colNames[i] for i in total_colNames_index )\n",
    "    print(skb_total)\n",
    "    print('SelectKBest의 갯수',len(skb_total))\n",
    "    \n",
    "    sc  = StandardScaler()\n",
    "    new_df = sc.fit_transform(X_st)\n",
    "    new_df_test = sc.fit_transform(X_st_test)\n",
    "    \n",
    "    X_total = pd.DataFrame(new_df, columns = skb_total )\n",
    "    X_total_test = pd.DataFrame(new_df_test, columns = skb_total)\n",
    "    print('feature 개수 : ',len(skb_total))\n",
    "    a = stacking(svm,  dt_clf, lgbm_clf, knn_clf,rf_pred,nb_pred,ada_clf,lr_clf, final_clf,X_total,X_total_test\n",
    "             ,y_train,y_test)\n",
    "    a = a[0]\n",
    "    print('----------------')\n",
    "    b[i] = a\n",
    "    end = time.time()\n",
    "    total_time = end - start\n",
    "    c.append(total_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('attack_cat', axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop('attack_cat', axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[453.2051692008972]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      43\n",
       "0  91.64\n",
       "1  97.61\n",
       "2  90.79\n",
       "3  94.08"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[454.22031593322754]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 175341)\n",
      "(175341, 6)\n",
      "Stacking 모델의 예측 정확도 : \n",
      "Accuracy \t 93.03% ,\n",
      " Precision \t99.32%,\n",
      " Recall \t91.22%,\n",
      " F1_score \t95.10%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.03, 99.32, 91.22, 95.1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.array([ dt_pred,\n",
    "                   lgbm_pred, lr_pred,  ada_pred, knn_pred,svm])\n",
    "print(preds.shape)\n",
    "preds= np.transpose(preds) # or pred.T\n",
    "print(preds.shape)\n",
    "final_clf =  LGBMClassifier(random_state = 1)\n",
    "\n",
    "final_clf.fit(preds, y_test)\n",
    "finalr_pred = final_clf.predict(preds)\n",
    "print('Stacking 모델의 예측 정확도 : ')\n",
    "accuracy(finalr_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
